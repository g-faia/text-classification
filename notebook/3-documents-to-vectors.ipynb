{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Documents to Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gfaia/Applications/anaconda/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import sys, argparse\n",
    "sys.path.append('..')\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "import gensim\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data from disk\n",
    "pos_examples = [s.decode(\"utf-8\", \"ignore\").strip() \n",
    "                for s in list(open(helper.mr_pos_data, mode=\"rb\").readlines())]\n",
    "neg_examples = [s.decode(\"utf-8\", \"ignore\").strip() \n",
    "                for s in list(open(helper.mr_neg_data, mode=\"rb\").readlines())]\n",
    "pos_nums, neg_nums = len(pos_examples), len(neg_examples)\n",
    "\n",
    "documents = pos_examples + neg_examples\n",
    "documents = [gensim.utils.simple_preprocess(doc) for doc in documents]\n",
    "\n",
    "pos_labels = [1 for _ in range(pos_nums)]\n",
    "neg_labels = [0 for _ in range(neg_nums)]\n",
    "\n",
    "labels = np.array(pos_labels + neg_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_corpus(documents, labels, split=0.1):\n",
    "    n_samples = len(documents)\n",
    "    split_ = int(n_samples * split)\n",
    "    \n",
    "    shuffle_indices = np.random.permutation(n_samples)\n",
    "    corpus = [documents[i] for i in shuffle_indices]\n",
    "    labels  = [labels[i] for i in shuffle_indices]\n",
    "    \n",
    "    train_corpus, train_labels = corpus[split_:], labels[split_:]\n",
    "    test_corpus, test_labels = corpus[split_:], labels[split_:]\n",
    "    train_corpus = [TaggedDocument(doc, [i]) for i, doc in enumerate(train_corpus)]\n",
    "    return train_corpus, train_labels, test_corpus, test_labels\n",
    "\n",
    "train_corpus, train_labels, test_corpus, test_labels = preprocess_corpus(documents, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Training a doc2vec on movie review dataset\n",
    "\n",
    "The API provided by Gensim trains a doc2vec model by using the method illustrated in paper Le and Mikolov et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38 s, sys: 6.68 s, total: 44.7 s\n",
      "Wall time: 26.3 s\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=300, min_count=2, epochs=40)\n",
    "model.build_vocab(train_corpus)\n",
    "%time model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training a linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.68      0.68      4823\n",
      "          1       0.68      0.69      0.68      4773\n",
      "\n",
      "avg / total       0.68      0.68      0.68      9596\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "\n",
    "# train a linear classify\n",
    "X_train, y_train = model.docvecs.vectors_docs, train_labels\n",
    "\n",
    "svc = LinearSVC()\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "X_test = [model.infer_vector(doc) for doc in test_corpus]\n",
    "y_test = test_labels\n",
    "\n",
    "y_predicted = svc.predict(X_test)\n",
    "print(metrics.classification_report(y_predicted, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
